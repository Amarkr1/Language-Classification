#####################################################################
		
		PROJECT 2: COMP 551 - LANGUAGE CLASSIFICATION
		author: AMAR KUMAR[amar.kumar@mail.mcgill.ca]
			LITA FAN [lita.fan@mail.mcgill.ca]
			DEKLAN CHUNG [deklan.chung@mail.mcgill.ca]
			
#####################################################################

File descriptions:
---------------------------------------------

***naive bayes.py [Language: python] - generate predictions using the naives Bayes algorithm. 
-->input files: 
1)The input file has to be a file 'train_set_x_features.csv' whose all the columns are the features extracted from the training data. This file can be generated automatically by setting the 'savefile' variable in Language Classification.py to 1 or by simply executing the file generateFeatures.py
All the input files can be generated by either executing Language Classification.py or generateFeatures.py.
2)another input file is the 'train_set_y.csv' which is provided by the assignment itself.
3)'test_set_x_features.csv' which contains features of all the test data sets.

-->output file: The prediction on the test set is the output
=> selection = 1 : set this variable to 1 so that chi^2 selection can be made for 50 features. The number of features can also be adjusted by changing the value of k. 

[PS: This code is compatible with Python 2.7 only because of some dependencies]
---------------------------------------------

***knn.py [Language: python] - generate predictions using the k-nearest neighbors algorithm.

-->input and output files:
See description for naivebayes.py.

---------------------------------------------

***Language Classification.py [Language: python] - uses different library functions for language predictions and also for generating feature files
important parameters:
=>normalize - to shift the value of the feature vectors to their mean
normalize = 0 , this means do not shift the values to their means but values in this case turns out to be negative and hence we never set normalize=1

=>algo_code -  which algorithm to use for feature selection. 1: Linear-fitting using chi^2 technique and 2: RFE (recursive feature elimination)
algo_code = 1

=>savefiles - whether to save the files or not so that these files can be used by others for further testing of results
savefiles = 0 means none of the files are saved

=> writeCode - whether to write the data to files or not
writeCode = 0 means do not write

Just for the sake of completion the file Language Classification_featureSelection.py is also given incase a feature selection has to be made before executing the code

---------------------------------------------

***Language Classification_featureSelection [Language: python] - description same as the file Language Classification.py except feature selection can be performed in this file

=> select - whether to perform a selection algorithm on the dataset 
select = 0 means do not perform selection algorithm
=> other variable controls are same as the file Language Classification.py
 
---------------------------------------------

***generateFeatures.py [Language: python] - this is used to generate features for training set, test set and also creates the file 'train_set_x_features.csv' and 'test_set_x_features.csv' which can be used by the naive bayes.py
The file creates a small version of the features which allows the user to test it and have a visualization of the dataset

=>The variable create can be set to 1 for generating the feature file for the training and the test data.
create = 0

---------------------------------------------

***createEmsamble.py [Language: python]- creates an ensemble prediction of all the learners present in the path and generates two files  - (1) variation 1 as discussed in report i.e. based on mode ; (2) variation 2 as discussed in report i.e.
weighted sum
[proper paths need to be specified here]

---------------------------------------------

***compare_outputs.py  [Language: python] - compares the similarity between files in the 'ref_files' folder and the 'prediction' folder. This is to have an idea that the prediction which is being made is not way off.

---------------------------------------------

***Dataset_pie.m [Language: MATLAB] - plots the pie chart of the data distributions

---------------------------------------------

***test_train.m [Language: MATLAB] - plots the test train for different Machine Learning models with different sizes of test and train data

---------------------------------------------

***rf_trees.m [Language: MATLAB] - plots the validation and training accuracy of the random forest vs number of trees 

---------------------------------------------

***unicodeval_features.txt - this contains the unicode values of emojis and all the noise present in the data. This file is not for execution and is just used for reference purposes

---------------------------------------------
'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''{All the python codes are compatible with Python 2.7/3.6 unless specified.}''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

Problem with Kaggle account:
Initially I created the account with username ADL_P2 and my email id amar.kumar@mail.mcgill.ca but I verified my account using a phone number which was used and this resulted in my account getting blocked. So, I contacted kaggle 
but they couldn't help so. I used the same email id - amar.kumar@mail.mcgill.ca for creating another account with user name LR on the leader board. Finally, as a team we make the submission under the team name -'LazyLearner'
which can be used for evaluation 
